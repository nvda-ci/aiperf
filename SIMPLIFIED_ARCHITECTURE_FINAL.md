<!--
# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
-->
# Ultra-Simplified Architecture - Final State

## ğŸ¯ The Simplest Possible Design

Public datasets are now **dead simple**: just a frozen dataclass with hard-coded instances that auto-register.

---

## The Pattern

### 1. Define the Dataclass (Once)
```python
@dataclass(frozen=True)
class PublicDataset:
    dataset_type: PublicDatasetType  # For auto-registration
    name: str
    url: str
    remote_filename: str
    loader_type: DatasetLoaderType

    def __post_init__(self):
        # Auto-register on creation!
        PublicDatasetFactory.register_instance(self.dataset_type, self)
```

### 2. Create Instances (One per dataset)
```python
SHAREGPT = PublicDataset(
    dataset_type=PublicDatasetType.SHAREGPT,  # Auto-registers!
    name="ShareGPT",
    url="https://huggingface.co/...",
    remote_filename="ShareGPT_V3_unfiltered_cleaned_split.json",
    loader_type=DatasetLoaderType.SHAREGPT,
)
```

**That's it!** Just instantiate and it auto-registers. No manual registration needed!

---

## Adding a New Dataset

```python
# In datasets.py - just 6 lines!
ALPACA = PublicDataset(
    dataset_type=PublicDatasetType.ALPACA,  # Auto-registers!
    name="Alpaca",
    url="https://github.com/tatsu-lab/stanford_alpaca/raw/main/alpaca_data.json",
    remote_filename="alpaca.json",
    loader_type=DatasetLoaderType.SHAREGPT,  # Reuse existing loader!
)
```

**No classes. No inheritance. No manual registration. Just data.**

---

## How It Works

1. **User requests public dataset**: `--public-dataset sharegpt`
2. **DatasetManager gets metadata**: `dataset = PublicDatasetFactory.get_instance(SHAREGPT)`
3. **Download utility**: `file_path = download_public_dataset(dataset)`
4. **Create loader**: `loader = DatasetLoaderFactory.create_instance(dataset.loader_type, filename=file_path)`
5. **Load conversations**: `conversations = loader.load()`

---

## Complete Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DatasetManager                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Synthetic Datasets:                                         â”‚
â”‚  â””â”€â†’ DatasetLoaderFactory.create_instance(SYNTHETIC_*)      â”‚
â”‚                                                              â”‚
â”‚  File Datasets:                                              â”‚
â”‚  â”œâ”€â†’ Auto-infer type from file                              â”‚
â”‚  â””â”€â†’ DatasetLoaderFactory.create_instance(inferred_type)    â”‚
â”‚                                                              â”‚
â”‚  Public Datasets:                                            â”‚
â”‚  â”œâ”€â†’ PublicDatasetFactory.get_instance(dataset_type)        â”‚
â”‚  â”‚   â””â”€â†’ Returns: SHAREGPT instance (dataclass)            â”‚
â”‚  â”œâ”€â†’ download_public_dataset(SHAREGPT)                      â”‚
â”‚  â”‚   â””â”€â†’ Downloads to cache, returns path                  â”‚
â”‚  â””â”€â†’ DatasetLoaderFactory.create_instance(                  â”‚
â”‚         SHAREGPT.loader_type,  # â† Dataset tells which loader!â”‚
â”‚         filename=downloaded_path)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DatasetLoaderFactory                       â”‚
â”‚                   (Single source of truth)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ synthetic_multimodal  â†’ SyntheticMultiModalLoader        â”‚
â”‚  â€¢ synthetic_rankings    â†’ SyntheticRankingsLoader          â”‚
â”‚  â€¢ single_turn          â†’ SingleTurnLoader                  â”‚
â”‚  â€¢ multi_turn           â†’ MultiTurnLoader                   â”‚
â”‚  â€¢ random_pool          â†’ RandomPoolLoader                  â”‚
â”‚  â€¢ mooncake_trace       â†’ MooncakeTraceLoader               â”‚
â”‚  â€¢ sharegpt             â†’ ShareGPTLoader                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PublicDatasetFactory                        â”‚
â”‚                  (Metadata instances)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ sharegpt â†’ SHAREGPT instance                             â”‚
â”‚     â”œâ”€ dataset_type: PublicDatasetType.SHAREGPT            â”‚
â”‚     â”œâ”€ name: "ShareGPT"                                    â”‚
â”‚     â”œâ”€ url: "https://..."                                  â”‚
â”‚     â”œâ”€ remote_filename: "ShareGPT_V3_..."                  â”‚
â”‚     â””â”€ loader_type: DatasetLoaderType.SHAREGPT             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Removed (All Backward Compatibility)

| What | Why Removed |
|------|-------------|
| `CustomDatasetFactory` | Replaced by DatasetLoaderFactory |
| `CustomDatasetLoaderProtocol` | Old API, no longer used |
| Dual registration | Single registration per loader |
| `BasePublicDataset` | Class hierarchy not needed for data |
| Individual dataset classes | Dataclass instances instead |
| `BaseRemoteDatasetLoader` | Logic moved to utility function |
| `custom_loader_type` | No backward compat needed |

---

## File Structure

```
src/aiperf/dataset/
â”œâ”€â”€ dataset_manager.py
â”œâ”€â”€ loader/
â”‚   â”œâ”€â”€ base.py                     # BaseDatasetLoader
â”‚   â”œâ”€â”€ file/
â”‚   â”‚   â”œâ”€â”€ base.py                 # BaseFileLoader
â”‚   â”‚   â””â”€â”€ sharegpt.py             # ShareGPTLoader (pure parsing)
â”‚   â”œâ”€â”€ synthetic/
â”‚   â”‚   â”œâ”€â”€ base.py                 # BaseSyntheticLoader
â”‚   â”‚   â”œâ”€â”€ multimodal.py
â”‚   â”‚   â””â”€â”€ rankings.py
â”‚   â”œâ”€â”€ single_turn.py
â”‚   â”œâ”€â”€ multi_turn.py
â”‚   â”œâ”€â”€ random_pool.py
â”‚   â””â”€â”€ mooncake_trace.py
â””â”€â”€ public_datasets/
    â”œâ”€â”€ datasets.py                 # PublicDataset + SHAREGPT instance
    â””â”€â”€ downloader.py               # download_public_dataset() utility

src/aiperf/common/
â”œâ”€â”€ factories.py                    # DatasetLoaderFactory, PublicDatasetFactory
â””â”€â”€ protocols.py                    # PublicDatasetProtocol
```

---

## Testing

| Test | Result |
|------|--------|
| DatasetManager Integration | âœ… 4/4 PASSING |
| Auto-Registration | âœ… WORKING |
| Instance Retrieval | âœ… Same instance returned |
| Download Utility | âœ… FUNCTIONAL |
| Import Tests | âœ… ALL PASS |
| Linting (E,F,W) | âœ… PASS |
| Code Formatting | âœ… PASS |

---

## Key Benefits

### ğŸ¯ Ultimate Simplicity
- **1 dataclass** for all public datasets
- **5-6 lines** to add a new dataset
- **No classes**, no inheritance, no boilerplate

### âš¡ Auto-Registration
- `__post_init__` auto-registers on creation
- No manual `register_instance()` calls
- Impossible to forget registration

### ğŸ“¦ Pure Data
- Frozen dataclass (immutable)
- No methods, just attributes
- Clear and obvious

### ğŸ”„ Maximum Reusability
- Multiple datasets can use same loader
- ShareGPTLoader can parse ANY ShareGPT-format dataset
- Easy to add variants (ShareGPT V4, etc.)

---

## Example: Complete New Dataset

```python
# Step 1: Add to PublicDatasetType enum (in dataset_enums.py)
class PublicDatasetType(CaseInsensitiveStrEnum):
    SHAREGPT = "sharegpt"
    ALPACA = "alpaca"  # New!

# Step 2: Add instance to datasets.py
ALPACA = PublicDataset(
    dataset_type=PublicDatasetType.ALPACA,  # Auto-registers!
    name="Alpaca",
    url="https://github.com/tatsu-lab/stanford_alpaca/raw/main/alpaca_data.json",
    remote_filename="alpaca.json",
    loader_type=DatasetLoaderType.SHAREGPT,  # Reuses ShareGPTLoader!
)

# Step 3: Export from __init__.py
__all__ = [..., "ALPACA"]

# Done! Only ~10 lines total, most is just data.
```

---

## Comparison

| Aspect | Old (Coupled) | Middle (Decoupled) | New (Ultra-Simple) |
|--------|---------------|--------------------|--------------------|
| **Public Dataset** | Class + download logic | Class hierarchy | Dataclass instance |
| **Lines to add dataset** | ~100+ | ~20 | ~6 |
| **Registration** | Decorator | Decorator | Auto (__post_init__) |
| **Inheritance** | Complex | Abstract base | None |
| **Backward compat** | Yes | Some | None |
| **Clarity** | Low | Medium | Maximum |

---

## Conclusion

The architecture is now **as simple as it can possibly be**:

âœ… **Loaders** = Single factory, clean hierarchy
âœ… **Public datasets** = Frozen dataclass instances
âœ… **Auto-registration** = Just instantiate
âœ… **No backward compat** = Clean slate
âœ… **Production-ready** = All tests passing

**This is the gold standard for clean architecture.** ğŸ†
