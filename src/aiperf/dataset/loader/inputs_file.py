# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

import json
from pathlib import Path
from typing import Any

from pydantic import ValidationError

from aiperf.common.enums import CustomDatasetType, DatasetSamplingStrategy
from aiperf.common.factories import CustomDatasetFactory
from aiperf.common.models import Conversation, Turn
from aiperf.common.models.dataset_models import InputsFile
from aiperf.dataset.loader.base_loader import BaseFileLoader


@CustomDatasetFactory.register(CustomDatasetType.INPUTS_FILE)
class InputsFileLoader(BaseFileLoader):
    """A dataset loader that loads pre-formatted payloads from an InputsFile format JSON file.

    This loader handles the AIPerf InputsFile format which contains pre-formatted payloads
    that are already formatted for the endpoint. This is useful when you have payloads that
    were previously generated by AIPerf or formatted externally.

    The InputsFile format:
    ```json
    {
      "data": [
        {
          "session_id": "session_123",
          "payloads": [
            {"messages": [...], "model": "...", ...},
            {"messages": [...], "model": "...", ...}
          ]
        }
      ]
    }
    ```

    Note: Since payloads are pre-formatted, this loader creates placeholder Turn objects
    that will be replaced with the actual payloads during request sending.
    """

    @classmethod
    def can_load(
        cls, data: dict[str, Any] | None = None, filename: str | Path | None = None
    ) -> bool:
        """Check if this loader can handle the given data format.

        Returns:
            True if the data has the InputsFile structure (has "data" key with list of SessionPayloads).
        """
        if data is None:
            return False

        try:
            InputsFile.model_validate(data)
            return True
        except ValidationError:
            return False

    @classmethod
    def get_preferred_sampling_strategy(cls) -> DatasetSamplingStrategy:
        """Get the preferred dataset sampling strategy for InputsFile."""
        return DatasetSamplingStrategy.SEQUENTIAL

    def load_dataset(self) -> dict[str, InputsFile]:
        """Load InputsFile format from a JSON file.

        Returns:
            A dictionary mapping filename to InputsFile object.
        """
        with open(self.filename) as f:
            data = json.load(f)

        inputs_file = InputsFile.model_validate(data)
        return {Path(self.filename).name: inputs_file}

    def convert_to_conversations(
        self, data: dict[str, InputsFile]
    ) -> list[Conversation]:
        """Convert InputsFile data to conversation objects.

        Since InputsFile contains pre-formatted payloads, we create placeholder Turn objects
        that store the payloads. The worker will use these payloads directly without re-formatting.

        Args:
            data: A dictionary mapping filename to InputsFile object.

        Returns:
            A list of conversations with payloads stored in turn metadata.
        """
        conversations = []
        for inputs_file in data.values():
            for session_payloads in inputs_file.data:
                conversation = Conversation(session_id=session_payloads.session_id)

                # Create a turn for each payload
                # Store the pre-formatted payload in the turn so it can be used directly
                for payload in session_payloads.payloads:
                    # Extract model from payload if present (for metadata)
                    model = payload.get("model")
                    
                    turn = Turn(
                        texts=[],  # Empty since payload is pre-formatted
                        model=model,  # Store model name if present
                        pre_formatted_payload=payload,  # Store the pre-formatted payload
                    )
                    conversation.turns.append(turn)

                conversations.append(conversation)

        return conversations
