# SPDX-FileCopyrightText: Copyright (c) 2025-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
# ============================================================================
# AUTO-GENERATED FILE - DO NOT EDIT
# ============================================================================
# This file is automatically generated by tools/generate_plugin_enums.py
# Any manual changes will be overwritten on the next generation.
#
# To regenerate: python tools/generate_plugin_enums.py
# ============================================================================
"""
Type stubs for dynamically generated plugin enums.

These stubs provide IDE autocomplete and type checking for enum members
that are created dynamically at runtime from the plugin registry.
"""

from aiperf.common.enums import ExtensibleStrEnum

class PluginCategory(ExtensibleStrEnum):
    """
    Dynamic enum for plugin categories.

    Each category represents a type of plugin that can be registered
    and used within the AIPerf framework.
    """

    ARRIVAL_PATTERN = "arrival_pattern"
    """Interval generators determine inter-arrival times for request rate strategy.
    Controls the distribution of request timing (constant, Poisson, gamma, etc.).
    One-to-one mapping when using request_rate timing mode.
    """

    COMMUNICATION = "communication"
    """Communication backends provide the underlying transport for inter-service messaging.
    Supports ZMQ IPC (single-node) and ZMQ TCP (multi-node) communication.
    One-to-one mapping based on deployment configuration.
    """

    COMMUNICATION_CLIENT = "communication_client"
    """Communication clients implement different ZMQ socket patterns for messaging.
    Includes PUB/SUB, PUSH/PULL, REQUEST/REPLY, and streaming patterns.
    Internal infrastructure: automatically created by framework based on usage.
    """

    CONSOLE_EXPORTER = "console_exporter"
    """Console exporters display benchmark results and diagnostics to stdout.
    Provides formatted output for metrics, errors, telemetry, and traces.
    One-to-many mapping: multiple console exporters can be loaded simultaneously.
    """

    CUSTOM_DATASET_LOADER = "custom_dataset_loader"
    """Custom dataset loaders parse different JSONL file formats into conversations.
    Supports single-turn, multi-turn, random-pool, and trace formats.
    Auto-detection: loaders are tried in priority order based on can_load().
    """

    DATA_EXPORTER = "data_exporter"
    """Data exporters write benchmark results to files in various formats.
    Supports CSV, JSON, Parquet, and specialized export formats.
    One-to-many mapping: multiple exporters can be loaded simultaneously.
    """

    DATASET_BACKING_STORE = "dataset_backing_store"
    """Dataset backing stores manage conversation data on the DatasetManager side.
    Provides efficient storage for dataset distribution to workers.
    Handles streaming writes and finalization for client access.
    """

    DATASET_CLIENT_STORE = "dataset_client_store"
    """Dataset client stores read conversation data on the Worker side.
    Provides efficient access to datasets from backing stores.
    Supports zero-copy reads and O(1) lookup performance.
    """

    DATASET_COMPOSER = "dataset_composer"
    """Dataset composers create conversation datasets from various sources.
    Handles synthetic generation, custom file loading, and specialized formats.
    One-to-one mapping based on composer_type configuration.
    """

    DATASET_SAMPLER = "dataset_sampler"
    """Dataset samplers control how conversations are selected from the dataset.
    Supports random, sequential, and shuffle sampling strategies.
    One-to-one mapping based on sampling strategy configuration.
    """

    ENDPOINT = "endpoint"
    """Endpoints define how to format requests and parse responses for different APIs.
    Supports OpenAI-compatible, HuggingFace, Cohere, NIM, and custom API formats.
    One-to-one mapping based on endpoint_type configuration.
    """

    PLOT = "plot"
    """Plot handlers create different types of visualizations from benchmark data.
    Supports scatter, histogram, timeline, percentile bands, and multi-run comparisons.
    One-to-one mapping based on plot type selection.
    """

    RAMP = "ramp"
    """Ramp strategies control how values are gradually transitioned over time.
    Used for ramping concurrency limits, request rates, and other numeric parameters.
    Supports linear, exponential, and stochastic ramping patterns.
    """

    RECORD_PROCESSOR = "record_processor"
    """Record processors stream records and compute metrics in a distributed manner.
    First stage of metrics pipeline, handling per-record computations.
    One-to-many mapping: multiple processors can be loaded simultaneously.
    """

    RESULTS_PROCESSOR = "results_processor"
    """Results processors aggregate results from record processors and compute derived metrics.
    Final stage of metrics pipeline for aggregated statistics and summaries.
    One-to-many mapping: multiple processors can be loaded simultaneously.
    """

    SERVICE = "service"
    """Services are the core processes that make up the AIPerf distributed system.
    Each service runs in a separate process and communicates via ZMQ message bus.
    Includes SystemController, Workers, Managers, and processing services.
    """

    SERVICE_MANAGER = "service_manager"
    """Service managers orchestrate how services are launched and managed.
    Supports multiprocessing (single-node) and Kubernetes (multi-node) deployments.
    One-to-one mapping based on run_mode configuration.
    """

    TIMING_STRATEGY = "timing_strategy"
    """Timing strategies control request scheduling and credit issuance.
    Determines when requests are sent based on fixed schedules, request rates,
    or user-centric patterns. One-to-one mapping per benchmark run.
    """

    TRANSPORT = "transport"
    """Transports handle the network layer for sending requests to inference servers.
    Manages connection pooling, streaming, error handling, and TCP configuration.
    One-to-one mapping based on transport_type configuration.
    """

    UI = "ui"
    """UI components provide progress tracking and visualization during benchmark execution.
    Supports rich terminal dashboards, simple progress bars, or headless execution.
    One-to-one mapping based on ui configuration.
    """

    ZMQ_PROXY = "zmq_proxy"
    """ZMQ proxies provide message routing between different socket patterns.
    Includes XPUB/XSUB, DEALER/ROUTER, and PUSH/PULL proxy types.
    Internal infrastructure: automatically created by framework based on configuration.
    """

class ArrivalPattern(ExtensibleStrEnum):
    """
    Interval generators determine inter-arrival times for request rate strategy.
    Controls the distribution of request timing (constant, Poisson, gamma, etc.).
    One-to-one mapping when using request_rate timing mode.
    """

    CONCURRENCY_BURST = "concurrency_burst"
    """Generate intervals as soon as possible, up to a max concurrency limit. Only allowed when a request rate is not specified."""

    CONSTANT = "constant"
    """Generate intervals at a constant rate."""

    GAMMA = "gamma"
    """Generate intervals using a gamma distribution with tunable smoothness.
    Use --arrival-smoothness to control the shape parameter:
    - smoothness = 1.0: Equivalent to Poisson (exponential inter-arrivals)
    - smoothness < 1.0: More bursty/clustered arrivals
    - smoothness > 1.0: More regular/smooth arrivals
    """

    POISSON = "poisson"
    """Generate intervals using a poisson process."""

class CommunicationBackend(ExtensibleStrEnum):
    """
    Communication backends provide the underlying transport for inter-service messaging.
    Supports ZMQ IPC (single-node) and ZMQ TCP (multi-node) communication.
    One-to-one mapping based on deployment configuration.
    """

    ZMQ_IPC = "zmq_ipc"
    """ZMQ IPC communication backend for single-node deployments. Provides high-performance message passing over Unix domain sockets for same-machine communication."""

    ZMQ_TCP = "zmq_tcp"
    """ZMQ TCP communication backend for distributed multi-node deployments. Provides reliable message passing over TCP sockets for cross-machine communication."""

class CommClientType(ExtensibleStrEnum):
    """
    Communication clients implement different ZMQ socket patterns for messaging.
    Includes PUB/SUB, PUSH/PULL, REQUEST/REPLY, and streaming patterns.
    Internal infrastructure: automatically created by framework based on usage.
    """

    PUB = "pub"
    """ZMQ PUB client for publish-subscribe messaging pattern. Broadcasts messages to multiple subscribers with topic-based filtering support."""

    PULL = "pull"
    """ZMQ PULL client for pipeline messaging pattern. Receives messages from pushers in fair-queued fashion for work processing."""

    PUSH = "push"
    """ZMQ PUSH client for pipeline messaging pattern. Sends messages to workers in load-balanced fashion for distributed work distribution."""

    REPLY = "reply"
    """ZMQ ROUTER client for request-reply messaging pattern. Receives commands and sends responses to specific requesters with identity-based routing."""

    REQUEST = "request"
    """ZMQ DEALER client for request-reply messaging pattern. Sends commands and waits for responses with timeout support and retry logic."""

    STREAMING_DEALER = "streaming_dealer"
    """ZMQ DEALER client for streaming messaging pattern. Provides high-throughput streaming with flow control and backpressure management."""

    STREAMING_ROUTER = "streaming_router"
    """ZMQ ROUTER client for streaming messaging pattern. Receives high-throughput streams with identity-based routing and connection management."""

    SUB = "sub"
    """ZMQ SUB client for publish-subscribe messaging pattern. Receives broadcasts from publishers with topic filtering and subscription management."""

class ConsoleExporterType(ExtensibleStrEnum):
    """
    Console exporters display benchmark results and diagnostics to stdout.
    Provides formatted output for metrics, errors, telemetry, and traces.
    One-to-many mapping: multiple console exporters can be loaded simultaneously.
    """

    API_ERRORS = "api_errors"
    """Console exporter for API error details. Displays detailed error information for API request failures with grouped error analysis."""

    ERRORS = "errors"
    """Console exporter for error summary. Displays error counts and details to help diagnose failures during benchmark execution. Always loaded."""

    EXPERIMENTAL_METRICS = "experimental_metrics"
    """Console exporter for experimental metrics. Displays metrics under development or evaluation that may change in future releases. Not loaded by default."""

    HTTP_TRACE = "http_trace"
    """Console exporter for HTTP trace information. Displays detailed HTTP request/response traces for debugging network issues."""

    INTERNAL_METRICS = "internal_metrics"
    """Console exporter for internal system metrics. Displays AIPerf framework performance metrics for debugging and optimization. Loaded by default."""

    METRICS = "metrics"
    """Console exporter for primary benchmark metrics. Displays formatted metric tables to stdout for user-facing results. Always loaded."""

    TELEMETRY = "telemetry"
    """Console exporter for GPU telemetry metrics. Displays GPU utilization, memory, power, and temperature metrics to stdout. Loaded when telemetry is enabled."""

    USAGE_DISCREPANCY_WARNING = "usage_discrepancy_warning"
    """Console exporter for usage discrepancy warnings. Alerts when token counts from server differ significantly from client calculations. Always loaded."""

class CustomDatasetType(ExtensibleStrEnum):
    """
    Custom dataset loaders parse different JSONL file formats into conversations.
    Supports single-turn, multi-turn, random-pool, and trace formats.
    Auto-detection: loaders are tried in priority order based on can_load().
    """

    MOONCAKE_TRACE = "mooncake_trace"
    """Mooncake trace dataset loader for loading Alibaba Mooncake trace format with timestamp-based replay support. Designed for fixed_schedule timing mode."""

    MULTI_TURN = "multi_turn"
    """Multi-turn dataset loader supporting conversation sessions with turn delays and multi-modal content. Enables realistic multi-turn conversation replay with session management."""

    RANDOM_POOL = "random_pool"
    """Random pool dataset loader that creates conversations by randomly sampling from predefined pools of system/user/assistant messages with configurable distributions."""

    SINGLE_TURN = "single_turn"
    """Single-turn dataset loader supporting multi-modal data and client-side batching. Supports text, images, audio with optional timestamps or delays. Does NOT support multi-turn features."""

class DataExporterType(ExtensibleStrEnum):
    """
    Data exporters write benchmark results to files in various formats.
    Supports CSV, JSON, Parquet, and specialized export formats.
    One-to-many mapping: multiple exporters can be loaded simultaneously.
    """

    CSV = "csv"
    """CSV exporter for aggregated metrics. Exports benchmark results to CSV format for spreadsheet analysis and data processing. Always loaded."""

    JSON = "json"
    """JSON exporter for aggregated metrics. Exports benchmark results to JSON format with full metric details and structured data. Always loaded."""

    RAW_RECORD_AGGREGATOR = "raw_record_aggregator"
    """Raw record aggregator that consolidates raw JSONL files from multiple record processors into final output files. Enabled when export_level is RAW."""

    SERVER_METRICS_CSV = "server_metrics_csv"
    """CSV exporter for server metrics. Exports Prometheus server metrics to CSV format for spreadsheet analysis."""

    SERVER_METRICS_JSON = "server_metrics_json"
    """JSON exporter for server metrics. Exports Prometheus server metrics to JSON format with full metric details."""

    SERVER_METRICS_PARQUET = "server_metrics_parquet"
    """Parquet exporter for server metrics. Exports Prometheus server metrics to Parquet format for efficient columnar storage and analysis."""

    TIMESLICE_CSV = "timeslice_csv"
    """CSV exporter for timeslice metrics. Exports time-series metric data to CSV format for spreadsheet analysis and plotting."""

    TIMESLICE_JSON = "timeslice_json"
    """JSON exporter for timeslice metrics. Exports time-series metric data to JSON format for temporal analysis and visualization."""

class DatasetBackingStoreType(ExtensibleStrEnum):
    """
    Dataset backing stores manage conversation data on the DatasetManager side.
    Provides efficient storage for dataset distribution to workers.
    Handles streaming writes and finalization for client access.
    """

    MEMORY_MAP = "memory_map"
    """Memory-mapped file backing store for zero-copy worker access. Stores dataset in memory-mapped files for efficient sharing across processes."""

class DatasetClientStoreType(ExtensibleStrEnum):
    """
    Dataset client stores read conversation data on the Worker side.
    Provides efficient access to datasets from backing stores.
    Supports zero-copy reads and O(1) lookup performance.
    """

    MEMORY_MAP = "memory_map"
    """Memory-mapped file client store for zero-copy reads. Reads from memory-mapped files with O(1) lookup performance."""

class ComposerType(ExtensibleStrEnum):
    """
    Dataset composers create conversation datasets from various sources.
    Handles synthetic generation, custom file loading, and specialized formats.
    One-to-one mapping based on composer_type configuration.
    """

    CUSTOM = "custom"
    """Custom dataset composer that loads conversations from JSONL files. Supports single-turn, multi-turn, random-pool, and mooncake-trace formats with automatic format detection."""

    SYNTHETIC = "synthetic"
    """Synthetic dataset composer that generates multi-turn conversations with synthetic text, image, and audio payloads using configurable distributions. Supports variable turn counts and delays."""

    SYNTHETIC_RANKINGS = "synthetic_rankings"
    """Synthetic rankings dataset composer that generates ranking tasks with query and passage pairs for ranking model evaluation and benchmarking."""

class DatasetSamplingStrategy(ExtensibleStrEnum):
    """
    Dataset samplers control how conversations are selected from the dataset.
    Supports random, sequential, and shuffle sampling strategies.
    One-to-one mapping based on sampling strategy configuration.
    """

    RANDOM = "random"
    """Random sampler that randomly selects conversation IDs with replacement. Can return the same conversation ID multiple times before seeing all IDs. Uses derived RNG for reproducibility."""

    SEQUENTIAL = "sequential"
    """Sequential sampler that iterates through conversation IDs in order. When reaching the end, wraps around to the beginning indefinitely. Completely deterministic with no randomness."""

    SHUFFLE = "shuffle"
    """Shuffle sampler that randomly samples without replacement, then repeats. Ensures all conversations are seen before any repetition, similar to music shuffle. Uses derived RNG for reproducibility."""

class EndpointType(ExtensibleStrEnum):
    """
    Endpoints define how to format requests and parse responses for different APIs.
    Supports OpenAI-compatible, HuggingFace, Cohere, NIM, and custom API formats.
    One-to-one mapping based on endpoint_type configuration.
    """

    CHAT = "chat"
    """OpenAI Chat Completions endpoint. Supports multi-modal inputs (text, images, audio, video) and both streaming and non-streaming responses. Uses /v1/chat/completions path."""

    COHERE_RANKINGS = "cohere_rankings"
    """Cohere Rankings endpoint. Provides document ranking capabilities using Cohere's reranking API."""

    COMPLETIONS = "completions"
    """OpenAI Completions endpoint. Supports text completions with streaming for legacy completion-based models. Uses /v1/completions path."""

    EMBEDDINGS = "embeddings"
    """OpenAI Embeddings endpoint. Generates vector embeddings for text inputs using embedding models. Uses /v1/embeddings path. Non-streaming only."""

    HF_TEI_RANKINGS = "hf_tei_rankings"
    """Hugging Face TEI (Text Embeddings Inference) Rankings endpoint. Provides ranking using TEI reranking models."""

    HUGGINGFACE_GENERATE = "huggingface_generate"
    """Hugging Face TGI (Text Generation Inference) endpoint. Supports both streaming (/generate_stream) and non-streaming (/generate) text generation."""

    IMAGE_GENERATION = "image_generation"
    """OpenAI Image Generation endpoint. Generates images from text prompts using models like DALL-E. Supports streaming responses. Uses /v1/images/generations path."""

    NIM_RANKINGS = "nim_rankings"
    """NVIDIA NIM Rankings endpoint. Processes ranking requests by taking a query and passages, returning relevance scores. Uses /v1/ranking path."""

    SOLIDO_RAG = "solido_rag"
    """Solido RAG endpoint. Custom endpoint for Solido RAG pipeline integration with retrieval-augmented generation."""

    TEMPLATE = "template"
    """Template endpoint for creating custom endpoint implementations. Serves as a starting point for plugin developers to implement new API formats."""

class PlotType(ExtensibleStrEnum):
    """
    Plot handlers create different types of visualizations from benchmark data.
    Supports scatter, histogram, timeline, percentile bands, and multi-run comparisons.
    One-to-one mapping based on plot type selection.
    """

    AREA = "area"
    """Area chart handler for visualizing cumulative metrics over time with shaded regions."""

    DUAL_AXIS = "dual_axis"
    """Dual-axis plot handler for comparing two metrics with different scales on the same chart."""

    HISTOGRAM = "histogram"
    """Histogram handler for showing metric value distributions across bins."""

    PARETO = "pareto"
    """Pareto chart handler for multi-run comparison showing latency vs throughput trade-offs."""

    PERCENTILE_BANDS = "percentile_bands"
    """Percentile bands handler showing metric distributions with shaded percentile regions over time."""

    REQUEST_TIMELINE = "request_timeline"
    """Request timeline handler showing Gantt-style view of TTFT vs generation time per request."""

    SCATTER = "scatter"
    """Scatter plot handler for visualizing individual data points for each request."""

    SCATTER_LINE = "scatter_line"
    """Scatter line handler for multi-run comparison with connected data points."""

    SCATTER_WITH_PERCENTILES = "scatter_with_percentiles"
    """Scatter plot with rolling percentile trend lines (p50/p95/p99) overlaid."""

    TIMESLICE = "timeslice"
    """Timeslice handler for showing aggregated averages per time window."""

class RampType(ExtensibleStrEnum):
    """
    Ramp strategies control how values are gradually transitioned over time.
    Used for ramping concurrency limits, request rates, and other numeric parameters.
    Supports linear, exponential, and stochastic ramping patterns.
    """

    EXPONENTIAL = "exponential"
    """Exponential ease-in ramp strategy. Starts slow and accelerates toward target, providing gradual warmup before full load."""

    LINEAR = "linear"
    """Linear ramp strategy with configurable step size. Steps at evenly spaced intervals for predictable, uniform value transitions."""

    POISSON = "poisson"
    """Poisson ramp strategy with exponentially-distributed intervals. Provides stochastic burstiness while guaranteeing completion within duration."""

class RecordProcessorType(ExtensibleStrEnum):
    """
    Record processors stream records and compute metrics in a distributed manner.
    First stage of metrics pipeline, handling per-record computations.
    One-to-many mapping: multiple processors can be loaded simultaneously.
    """

    METRIC_RECORD = "metric_record"
    """Streaming record processor that computes metrics from MetricType.RECORD and MetricType.AGGREGATE. First stage of distributed processing pipeline. Always loaded."""

    RAW_RECORD_WRITER = "raw_record_writer"
    """Raw record writer that streams raw request/response data to JSONL files for detailed analysis and debugging. Enabled when export_level is RAW."""

class ResultsProcessorType(ExtensibleStrEnum):
    """
    Results processors aggregate results from record processors and compute derived metrics.
    Final stage of metrics pipeline for aggregated statistics and summaries.
    One-to-many mapping: multiple processors can be loaded simultaneously.
    """

    GPU_TELEMETRY_ACCUMULATOR = "gpu_telemetry_accumulator"
    """GPU telemetry accumulator that aggregates GPU telemetry records and computes metrics in a hierarchical structure. Loaded when telemetry is enabled."""

    GPU_TELEMETRY_JSONL_WRITER = "gpu_telemetry_jsonl_writer"
    """GPU telemetry JSONL writer that exports per-record GPU telemetry data to JSONL files as it arrives from GPUTelemetryManager. Enabled with telemetry export config."""

    METRIC_RESULTS = "metric_results"
    """Results processor that computes metrics from MetricType.DERIVED and aggregates results from all record processors. Final stage of metrics pipeline. Always loaded."""

    RECORD_EXPORT = "record_export"
    """Record export processor that writes per-record metrics to JSONL files with display unit conversion and filtering. Enabled when export_level is RECORDS."""

    SERVER_METRICS_ACCUMULATOR = "server_metrics_accumulator"
    """Server metrics accumulator that aggregates Prometheus server metrics records and computes summary statistics. Supports Gauge, Counter, and Histogram metrics."""

    SERVER_METRICS_JSONL_WRITER = "server_metrics_jsonl_writer"
    """Server metrics JSONL writer that exports per-record server metrics data to JSONL files in slim format."""

    TIMESLICE = "timeslice"
    """Timeslice results processor that computes metrics for user-configurable time slices, enabling time-series analysis of benchmark performance. Enabled when timeslice config is set."""

class ServiceType(ExtensibleStrEnum):
    """
    Services are the core processes that make up the AIPerf distributed system.
    Each service runs in a separate process and communicates via ZMQ message bus.
    Includes SystemController, Workers, Managers, and processing services.
    """

    DATASET_MANAGER = "dataset_manager"
    """Dataset management service. Handles prompt/token generation, dataset loading and composition, conversation sampling, and distribution to timing manager."""

    GPU_TELEMETRY_MANAGER = "gpu_telemetry_manager"
    """GPU telemetry collection service using DCGM. Monitors GPU metrics (utilization, memory, power, temperature) during benchmark execution for performance analysis."""

    RECORD_PROCESSOR = "record_processor"
    """Record processing service for metric computation. Scales with load to process streaming records and compute per-record and aggregate metrics in a distributed manner."""

    RECORDS_MANAGER = "records_manager"
    """Record aggregation and results management service. Aggregates metrics from all record processors, manages results processors, and coordinates final results export."""

    SERVER_METRICS_MANAGER = "server_metrics_manager"
    """Server metrics collection service using Prometheus. Monitors server-side metrics from inference servers during benchmark execution."""

    SYSTEM_CONTROLLER = "system_controller"
    """System orchestration and lifecycle management service. Coordinates all other services, manages benchmark phases (warmup/profiling), and controls overall execution flow."""

    TIMING_MANAGER = "timing_manager"
    """Request scheduling and credit issuance service. Controls timing of requests using fixed schedule or request rate strategies with credit-based flow control."""

    WORKER = "worker"
    """Worker service that executes LLM API calls and maintains conversation state. Scaled horizontally for throughput. Handles sticky routing for multi-turn conversations."""

    WORKER_MANAGER = "worker_manager"
    """Worker lifecycle and health monitoring service. Manages worker pool, monitors health metrics, handles worker failures, and coordinates worker scaling."""

class ServiceRunType(ExtensibleStrEnum):
    """
    Service managers orchestrate how services are launched and managed.
    Supports multiprocessing (single-node) and Kubernetes (multi-node) deployments.
    One-to-one mapping based on run_mode configuration.
    """

    KUBERNETES = "kubernetes"
    """Kubernetes service manager for multi-node deployments. Runs each service as a Kubernetes pod with ZMQ TCP communication for distributed cloud execution."""

    MULTIPROCESSING = "multiprocessing"
    """Multiprocess service manager for single-node deployments. Runs each service as a separate process with ZMQ IPC communication for high-performance local execution."""

class TimingMode(ExtensibleStrEnum):
    """
    Timing strategies control request scheduling and credit issuance.
    Determines when requests are sent based on fixed schedules, request rates,
    or user-centric patterns. One-to-one mapping per benchmark run.
    """

    FIXED_SCHEDULE = "fixed_schedule"
    """A mode where the TimingManager will send requests according to a fixed schedule."""

    REQUEST_RATE = "request_rate"
    """A mode where the TimingManager will send requests using a request rate generator based on various modes.
    Optionally, a max concurrency limit can be specified as well.
    """

    USER_CENTRIC_RATE = "user_centric_rate"
    """A mode where each session acts as a separate user with gap = num_users / request_rate between turns.
    Users block on their previous turn (no interleaving within a user).
    Matches LMBenchmark behavior for KV cache benchmarking.
    """

class TransportType(ExtensibleStrEnum):
    """
    Transports handle the network layer for sending requests to inference servers.
    Manages connection pooling, streaming, error handling, and TCP configuration.
    One-to-one mapping based on transport_type configuration.
    """

    HTTP = "http"
    """HTTP/1.1 transport implementation using aiohttp. Provides high-performance async HTTP client with connection pooling, SSE streaming support, automatic error handling, and custom TCP connector configuration."""

class UIType(ExtensibleStrEnum):
    """
    UI components provide progress tracking and visualization during benchmark execution.
    Supports rich terminal dashboards, simple progress bars, or headless execution.
    One-to-one mapping based on ui configuration.
    """

    DASHBOARD = "dashboard"
    """Rich terminal dashboard UI with real-time progress tracking, metric updates, and visual components using Textual framework. Provides interactive TUI experience."""

    NONE = "none"
    """No-op UI implementation. Disables all UI output for headless execution, automation scripts, or when output is not desired."""

    SIMPLE = "simple"
    """Simple progress bar UI using tqdm. Provides lightweight progress tracking suitable for simple terminals and logs with minimal resource overhead."""

class ZMQProxyType(ExtensibleStrEnum):
    """
    ZMQ proxies provide message routing between different socket patterns.
    Includes XPUB/XSUB, DEALER/ROUTER, and PUSH/PULL proxy types.
    Internal infrastructure: automatically created by framework based on configuration.
    """

    DEALER_ROUTER = "dealer_router"
    """DEALER/ROUTER proxy for request-reply pattern. Routes messages between DEALER clients and ROUTER services with identity-based routing and response forwarding."""

    PUSH_PULL = "push_pull"
    """PUSH/PULL proxy for pipeline pattern. Routes messages from PUSH clients to PULL services with load-balanced work distribution."""

    XPUB_XSUB = "xpub_xsub"
    """XPUB/XSUB proxy for publish-subscribe pattern. Routes messages from PUB clients to SUB services with subscription management and message broadcasting."""

__all__ = [
    "ArrivalPattern",
    "CommClientType",
    "CommunicationBackend",
    "ComposerType",
    "ConsoleExporterType",
    "CustomDatasetType",
    "DataExporterType",
    "DatasetBackingStoreType",
    "DatasetClientStoreType",
    "DatasetSamplingStrategy",
    "EndpointType",
    "PlotType",
    "PluginCategory",
    "RampType",
    "RecordProcessorType",
    "ResultsProcessorType",
    "ServiceRunType",
    "ServiceType",
    "TimingMode",
    "TransportType",
    "UIType",
    "ZMQProxyType",
]
