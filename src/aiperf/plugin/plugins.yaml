# SPDX-FileCopyrightText: Copyright (c) 2025-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
# yaml-language-server: $schema=schema/plugins.schema.json

# =============================================================================
# AIPerf Built-in Plugin Registry
# =============================================================================
# Schema version: 1.0
#
# Format:
#   name:
#     class: module.path:ClassName
#     description: Human-readable description (required)
#     priority: int (optional, default: 0, for conflict resolution only)
#     metadata: (optional) Category-specific metadata values, schema defined in categories.yaml
# =============================================================================

schema_version: "1.0"

package:
  name: aiperf
  version: "2.0.0"
  description: AIPerf core implementations for AI benchmarking
  author: NVIDIA
  license: Apache-2.0
  homepage: https://github.com/ai-dynamo/aiperf

# =============================================================================
# Record Processors
# =============================================================================
# Record processors stream records and compute metrics in a distributed manner.
# One-to-many mapping: multiple processors can be loaded simultaneously.
# =============================================================================
record_processor:
  metric_record:
    class: aiperf.post_processors.metric_record_processor:MetricRecordProcessor
    description: Streaming record processor that computes metrics from MetricType.RECORD and MetricType.AGGREGATE. First stage of distributed processing pipeline. Always loaded.

  raw_record_writer:
    class: aiperf.post_processors.raw_record_writer_processor:RawRecordWriterProcessor
    description: Raw record writer that streams raw request/response data to JSONL files for detailed analysis and debugging. Enabled when export_level is RAW.

# =============================================================================
# Results Processors
# =============================================================================
# Results processors aggregate results from record processors and compute derived metrics.
# One-to-many mapping: multiple processors can be loaded simultaneously.
# =============================================================================
results_processor:
  metric_results:
    class: aiperf.post_processors.metric_results_processor:MetricResultsProcessor
    description: Results processor that computes metrics from MetricType.DERIVED and aggregates results from all record processors. Final stage of metrics pipeline. Always loaded.

  record_export:
    class: aiperf.post_processors.record_export_results_processor:RecordExportResultsProcessor
    description: Record export processor that writes per-record metrics to JSONL files with display unit conversion and filtering. Enabled when export_level is RECORDS.

  gpu_telemetry_accumulator:
    class: aiperf.gpu_telemetry.accumulator:GPUTelemetryAccumulator
    description: GPU telemetry accumulator that aggregates GPU telemetry records and computes metrics in a hierarchical structure. Loaded when telemetry is enabled.

  gpu_telemetry_jsonl_writer:
    class: aiperf.gpu_telemetry.jsonl_writer:GPUTelemetryJSONLWriter
    description: GPU telemetry JSONL writer that exports per-record GPU telemetry data to JSONL files as it arrives from GPUTelemetryManager. Enabled with telemetry export config.

  server_metrics_accumulator:
    class: aiperf.server_metrics.accumulator:ServerMetricsAccumulator
    description: Server metrics accumulator that aggregates Prometheus server metrics records and computes summary statistics. Supports Gauge, Counter, and Histogram metrics.

  server_metrics_jsonl_writer:
    class: aiperf.server_metrics.jsonl_writer:ServerMetricsJSONLWriter
    description: Server metrics JSONL writer that exports per-record server metrics data to JSONL files in slim format.

  timeslice:
    class: aiperf.post_processors.timeslice_metric_results_processor:TimesliceMetricResultsProcessor
    description: Timeslice results processor that computes metrics for user-configurable time slices, enabling time-series analysis of benchmark performance. Enabled when timeslice config is set.

# =============================================================================
# Data Exporters
# =============================================================================
# Data exporters write benchmark results to files in various formats.
# One-to-many mapping: multiple exporters can be loaded simultaneously.
# =============================================================================
data_exporter:
  csv:
    class: aiperf.exporters.metrics_csv_exporter:MetricsCsvExporter
    description: CSV exporter for aggregated metrics. Exports benchmark results to CSV format for spreadsheet analysis and data processing. Always loaded.

  json:
    class: aiperf.exporters.metrics_json_exporter:MetricsJsonExporter
    description: JSON exporter for aggregated metrics. Exports benchmark results to JSON format with full metric details and structured data. Always loaded.

  raw_record_aggregator:
    class: aiperf.post_processors.raw_record_writer_processor:RawRecordAggregator
    description: Raw record aggregator that consolidates raw JSONL files from multiple record processors into final output files. Enabled when export_level is RAW.

  server_metrics_csv:
    class: aiperf.server_metrics.csv_exporter:ServerMetricsCsvExporter
    description: CSV exporter for server metrics. Exports Prometheus server metrics to CSV format for spreadsheet analysis.

  server_metrics_json:
    class: aiperf.server_metrics.json_exporter:ServerMetricsJsonExporter
    description: JSON exporter for server metrics. Exports Prometheus server metrics to JSON format with full metric details.

  server_metrics_parquet:
    class: aiperf.server_metrics.parquet_exporter:ServerMetricsParquetExporter
    description: Parquet exporter for server metrics. Exports Prometheus server metrics to Parquet format for efficient columnar storage and analysis.

  timeslice_csv:
    class: aiperf.exporters.timeslice_metrics_csv_exporter:TimesliceMetricsCsvExporter
    description: CSV exporter for timeslice metrics. Exports time-series metric data to CSV format for spreadsheet analysis and plotting.

  timeslice_json:
    class: aiperf.exporters.timeslice_metrics_json_exporter:TimesliceMetricsJsonExporter
    description: JSON exporter for timeslice metrics. Exports time-series metric data to JSON format for temporal analysis and visualization.

# =============================================================================
# Console Exporters
# =============================================================================
# Console exporters display benchmark results and diagnostics to stdout.
# One-to-many mapping: multiple console exporters can be loaded simultaneously.
# =============================================================================
console_exporter:
  api_errors:
    class: aiperf.exporters.console_api_error_exporter:ConsoleApiErrorExporter
    description: Console exporter for API error details. Displays detailed error information for API request failures with grouped error analysis.

  errors:
    class: aiperf.exporters.console_error_exporter:ConsoleErrorExporter
    description: Console exporter for error summary. Displays error counts and details to help diagnose failures during benchmark execution. Always loaded.

  experimental_metrics:
    class: aiperf.exporters.experimental_metrics_console_exporter:ConsoleExperimentalMetricsExporter
    description: Console exporter for experimental metrics. Displays metrics under development or evaluation that may change in future releases. Not loaded by default.

  http_trace:
    class: aiperf.exporters.http_trace_console_exporter:HttpTraceConsoleExporter
    description: Console exporter for HTTP trace information. Displays detailed HTTP request/response traces for debugging network issues.

  internal_metrics:
    class: aiperf.exporters.internal_metrics_console_exporter:ConsoleInternalMetricsExporter
    description: Console exporter for internal system metrics. Displays AIPerf framework performance metrics for debugging and optimization. Loaded by default.

  metrics:
    class: aiperf.exporters.console_metrics_exporter:ConsoleMetricsExporter
    description: Console exporter for primary benchmark metrics. Displays formatted metric tables to stdout for user-facing results. Always loaded.

  telemetry:
    class: aiperf.exporters.gpu_telemetry_console_exporter:GPUTelemetryConsoleExporter
    description: Console exporter for GPU telemetry metrics. Displays GPU utilization, memory, power, and temperature metrics to stdout. Loaded when telemetry is enabled.

  usage_discrepancy_warning:
    class: aiperf.exporters.console_usage_discrepancy_exporter:ConsoleUsageDiscrepancyExporter
    description: Console exporter for usage discrepancy warnings. Alerts when token counts from server differ significantly from client calculations. Always loaded.

# =============================================================================
# Transports
# =============================================================================
# Transports handle the network layer for sending requests to inference servers.
# One-to-one mapping: exactly one transport is selected based on transport_type.
# =============================================================================
transport:
  http:
    class: aiperf.transports.aiohttp_transport:AioHttpTransport
    description: HTTP/1.1 transport implementation using aiohttp. Provides high-performance async HTTP client with connection pooling, SSE streaming support, automatic error handling, and custom TCP connector configuration.
    metadata:
      transport_type: http
      url_schemes: [http, https]

# =============================================================================
# UI Components
# =============================================================================
# UI components provide progress tracking and visualization during benchmark execution.
# One-to-one mapping: exactly one UI is selected based on ui config.
# =============================================================================
ui:
  dashboard:
    class: aiperf.ui.dashboard.aiperf_dashboard_ui:AIPerfDashboardUI
    description: Rich terminal dashboard UI with real-time progress tracking, metric updates, and visual components using Textual framework. Provides interactive TUI experience.

  none:
    class: aiperf.ui.no_ui:NoUI
    description: No-op UI implementation. Disables all UI output for headless execution, automation scripts, or when output is not desired.

  simple:
    class: aiperf.ui.tqdm_ui:TQDMProgressUI
    description: Simple progress bar UI using tqdm. Provides lightweight progress tracking suitable for simple terminals and logs with minimal resource overhead.

# =============================================================================
# Services
# =============================================================================
# Services are the core processes that make up the AIPerf distributed system.
# Each service runs in a separate process and communicates via ZMQ message bus.
# =============================================================================
service:
  dataset_manager:
    class: aiperf.dataset.dataset_manager:DatasetManager
    description: Dataset management service. Handles prompt/token generation, dataset loading and composition, conversation sampling, and distribution to timing manager.

  record_processor:
    class: aiperf.records.record_processor_service:RecordProcessor
    description: Record processing service for metric computation. Scales with load to process streaming records and compute per-record and aggregate metrics in a distributed manner.

  records_manager:
    class: aiperf.records.records_manager:RecordsManager
    description: Record aggregation and results management service. Aggregates metrics from all record processors, manages results processors, and coordinates final results export.

  system_controller:
    class: aiperf.controller.system_controller:SystemController
    description: System orchestration and lifecycle management service. Coordinates all other services, manages benchmark phases (warmup/profiling), and controls overall execution flow.

  gpu_telemetry_manager:
    class: aiperf.gpu_telemetry.manager:GPUTelemetryManager
    description: GPU telemetry collection service using DCGM. Monitors GPU metrics (utilization, memory, power, temperature) during benchmark execution for performance analysis.

  server_metrics_manager:
    class: aiperf.server_metrics.manager:ServerMetricsManager
    description: Server metrics collection service using Prometheus. Monitors server-side metrics from inference servers during benchmark execution.

  timing_manager:
    class: aiperf.timing.manager:TimingManager
    description: Request scheduling and credit issuance service. Controls timing of requests using fixed schedule or request rate strategies with credit-based flow control.

  worker:
    class: aiperf.workers.worker:Worker
    description: Worker service that executes LLM API calls and maintains conversation state. Scaled horizontally for throughput. Handles sticky routing for multi-turn conversations.

  worker_manager:
    class: aiperf.workers.worker_manager:WorkerManager
    description: Worker lifecycle and health monitoring service. Manages worker pool, monitors health metrics, handles worker failures, and coordinates worker scaling.

# =============================================================================
# Service Managers
# =============================================================================
# Service managers orchestrate how services are launched and managed.
# One-to-one mapping: exactly one service manager is selected based on run_mode.
# =============================================================================
service_manager:
  kubernetes:
    class: aiperf.controller.kubernetes_service_manager:KubernetesServiceManager
    description: Kubernetes service manager for multi-node deployments. Runs each service as a Kubernetes pod with ZMQ TCP communication for distributed cloud execution.

  multiprocessing:
    class: aiperf.controller.multiprocess_service_manager:MultiProcessServiceManager
    description: Multiprocess service manager for single-node deployments. Runs each service as a separate process with ZMQ IPC communication for high-performance local execution.
